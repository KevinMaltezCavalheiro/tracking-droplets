Considering this paper as a reference (<https://pubs.rsc.org/en/content/articlelanding/2013/lc/c3lc50074h>), the first droplet detection algorithm was developed. The main issue encountered with this approach is handling droplets attached to walls or when droplets come into contact with each other. When a droplet touches the wall, background subtraction tends to split the droplet, making proper filling impossible afterward. When droplets come into contact, filling occurs across all contacted objects, causing several droplets to be perceived as a single entity. Moreover, this model requires a complete video to perform background subtraction through the modal image, leading to significant computation time during the first run. Although the resulting image can be saved for later use.

To overcome these limitations, another approach has been implemented focusing solely on droplet detection rather than attempting general object movement detection. After many trials and errors, the Python script employs a straightforward method without any background subtraction or filling. New issues naturally arrised due to the varying lighting conditions and the difficulties to distinguish droplets, oil, channels, PDMS, or other elements within the system. Here, individual operations are applied to each frame independently while highlighting local contours using a combination of the blackhat operation and local thresholding from python.

Contours are then extracted, but determining whether they represent actual droplets remains challenging due to their similarity with other features. To address this, geometric properties like area, perimeter, circularity,... are recorded for each identified object. Objects touching the border of the image are automatically rejected since partial droplets could skew results. These remaining properties are fed into an SVC model from the sklearn library from python, allowing cluster separation for different groups of contours.

The `training\_svc\_blackhat.py` script trains the model using input videos, displaying the original images along with the detected contours sequentially. Users mark detected droplet contours with "y" and others with "n." Once completed, new data points are added to existing ones before training the final model. Eighty percent of the dataset is used for training, while twenty percent serves as a testing set, enabling precision checks. Training data, test data, and the trained model (`scaler.joblib`, `svm\_model.joblib`) are stored in the `svc` directory, ready to apply to new images for inferring droplet locations. Feel free to utilize the provided pretrained model or train your own.