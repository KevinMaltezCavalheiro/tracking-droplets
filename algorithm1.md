 ### Considering this paper as a reference (<https://pubs.rsc.org/en/content/articlelanding/2013/lc/c3lc50074h>), the first drop detection algorithm was developed. The main issue encountered with this approach is handling drops attached to walls or when drops come into contact with each other. When a drop touches the wall, background subtraction tends to split the drop, making proper filling impossible afterward. When drops come into contact, filling occurs across all contacted objects, causing several drops to be perceived as a single entity. Moreover, this model requires a complete video to perform background subtraction using temporal differencing, leading to significant computation time during the first run. Although the resulting image can be saved for later use.

To overcome these limitations, another approach has been implemented focusing solely on drop detection rather than attempting general object movement detection. After many trials and errors, the Python script employs a straightforward method without any background subtraction or filling, avoiding issues caused by varying lighting conditions and difficulties distinguishing between drops, oil, channels, PDMS, or other elements within the system. Instead, individual operations are applied to each frame independently while highlighting local edges using a combination of the blackhat operation and local thresholding.

Contours are then extracted, but determining whether they represent actual droplets remains challenging due to their similarity with other features. To address this, geometric properties like area, perimeter, and circularity are recorded for each identified object. Objects touching the border of the image are automatically rejected since partial droplets could skew results. These remaining properties are fed into an SVC model from the sklearn library, allowing cluster separation for different groups of contours.

The "training\_svc\_blackhat.py" script trains the model using input videos, displaying the original images along with the detected contours sequentially. Users mark detected drop contours with "y" and others with "n." Once completed, new data points are added to existing ones before training the final model. Eighty percent of the dataset is used for training, while twenty percent serves as a testing set, enabling precision checks. Training data, test data, and the trained model ("scaler.joblib," "svm\_model.joblib") are stored in the "svc" directory, ready to apply to new images for inferring droplet locations. Feel free to utilize the provided pretrained model or train your own.